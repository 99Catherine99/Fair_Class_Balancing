{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fairBalance import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing(X_train, target, knn, sensitive_attribute, features, drop_features, continous_features):\n",
    "    fcb = fairBalance(X_train, features, continous_features, drop_features, sensitive_attribute, target, knn = knn)\n",
    "    fcb.fit()\n",
    "    X_balanced, y_balanced = fcb.generater()\n",
    "    \n",
    "    return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_train, y_train, X_test, features):\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test[features])\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(X_test, y_pred, target, sensitive_attribute, priority_group):\n",
    "    y_test = X_test[target]\n",
    "\n",
    "    df_pred = pd.DataFrame()\n",
    "    df_pred[sensitive_attribute]=X_test[sensitive_attribute].tolist()\n",
    "    df_pred['truth']=y_test.tolist()\n",
    "    df_pred['pred']=y_pred\n",
    "    print(\"---- overall performance ----\")\n",
    "    performance(df_pred)\n",
    "    print(\"---- performance of different groups ----\")\n",
    "    group_comp(df_pred, sensitive_attribute, priority_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example with COMPAS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. reading the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../compas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. set all required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=5\n",
    "target='two_year_recid'\n",
    "drop_features=['race','sex']\n",
    "features=list(set(df.keys().tolist())-set(drop_features+[target]))\n",
    "continous_features=['age','juv_fel_count','juv_misd_count','juv_other_count','priors_count']\n",
    "sensitive_attribute = 'race'\n",
    "privileged_group = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. separate train-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.2, stratify=df[target], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. balance the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster the original dataset into 6 clusters:\n",
      "Removing 1233 samples from the original dataset...\n"
     ]
    }
   ],
   "source": [
    "X_balanced, y_balanced = balancing(X_train, target, knn, sensitive_attribute, features, drop_features, continous_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.prediction & performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Performance before balancing ======== \n",
      "---- overall performance ----\n",
      "Test Accuracy  0.6766612641815235\n",
      "Precision: 0.675828\n",
      "Recall: 0.676661\n",
      "F1: 0.673415\n",
      "---- performance of different groups ----\n",
      "+----------------+-------+-------+-------+-------+\n",
      "| Group          |    F1 |   TPR |   FPR |    PR |\n",
      "|----------------+-------+-------+-------+-------|\n",
      "| Privileged     | 0.668 | 0.449 | 0.172 | 0.279 |\n",
      "| Non-privileged | 0.673 | 0.624 | 0.277 | 0.447 |\n",
      "+----------------+-------+-------+-------+-------+\n",
      "Equal Opportunity 0.174\n",
      "Equal Odds 0.140\n",
      "Statistical Parity 0.167\n",
      "======== Performance after balancing ======== \n",
      "---- overall performance ----\n",
      "Test Accuracy  0.63290113452188\n",
      "Precision: 0.631774\n",
      "Recall: 0.632901\n",
      "F1: 0.632078\n",
      "---- performance of different groups ----\n",
      "+----------------+-------+-------+-------+-------+\n",
      "| Group          |    F1 |   TPR |   FPR |    PR |\n",
      "|----------------+-------+-------+-------+-------|\n",
      "| Privileged     | 0.657 | 0.525 | 0.256 | 0.360 |\n",
      "| Non-privileged | 0.620 | 0.594 | 0.355 | 0.472 |\n",
      "+----------------+-------+-------+-------+-------+\n",
      "Equal Opportunity 0.069\n",
      "Equal Odds 0.084\n",
      "Statistical Parity 0.112\n"
     ]
    }
   ],
   "source": [
    "print(\"========= Performance before balancing ======== \")\n",
    "y_pred = prediction(X_train[features], X_train[target], X_test, features)\n",
    "evaluation(X_test, y_pred, target, sensitive_attribute, priority_group = 1)\n",
    "\n",
    "print(\"======== Performance after balancing ======== \")\n",
    "y_pred_bal = prediction(X_balanced, y_balanced, X_test, features)\n",
    "evaluation(X_test, y_pred_bal, target, sensitive_attribute, priority_group = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
